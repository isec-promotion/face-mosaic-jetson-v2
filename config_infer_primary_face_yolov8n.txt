[property]
# YOLOv8n ONNXモデルのパス
# Ultralyticsからエクスポートしたモデルを配置
onnx-file=models/yolov8n/yolov8n.pt.onnx

# TensorRTエンジンファイル（初回実行時に自動生成）
# model-engine-fileを指定すると、nvinferが正しくファイルを保存できないため、
# この行をコメントアウトして自動生成に任せる
model-engine-file=models/yolov8n/yolov8n_b1_fp16.engine

network-type=0                 # detector
num-detected-classes=80        # COCOデータセット（80クラス）
batch-size=1
gie-unique-id=1
network-mode=2                 # FP16推論
infer-dims=3;640;640           # 入力サイズ 640x640
maintain-aspect-ratio=1

# DeepStream-YOLOカスタムライブラリのパス
# ビルドしたライブラリの絶対パスを指定してください
custom-lib-path=/opt/nvidia/deepstream/deepstream-7.1/lib/libnvdsinfer_custom_impl_Yolo.so

# YOLOv8パーサー関数名
parse-bbox-func-name=NvDsInferParseYolo

# エンジン作成関数名
engine-create-func-name=NvDsInferYoloCudaEngineGet

# まず「全クラス」をほぼ全部落とす設定にする
[class-attrs-all]
pre-cluster-threshold=1.0      # 1.0 なのでほぼ何も通らない
nms-iou-threshold=0.50
topk=100

# そのうえで「person(class_id=0)」だけ閾値を下げて生かす
[class-attrs-0]
pre-cluster-threshold=0.30     # 人だけ 0.30 以上を通す
nms-iou-threshold=0.50
topk=100